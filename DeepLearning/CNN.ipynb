{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracted data of vibration and power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = pd.read_csv('C:/Users/intel/Desktop/Mtech_Proj/Digital twin_29 Jan 2021/extractedData_Vib_Pow.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014.1</th>\n",
       "      <th>1015.1</th>\n",
       "      <th>1016.1</th>\n",
       "      <th>1017.1</th>\n",
       "      <th>1018.1</th>\n",
       "      <th>1019.1</th>\n",
       "      <th>1020.1</th>\n",
       "      <th>1021.1</th>\n",
       "      <th>1022.1</th>\n",
       "      <th>1023.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067198</td>\n",
       "      <td>0.071802</td>\n",
       "      <td>0.226346</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>0.051415</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.191163</td>\n",
       "      <td>0.102382</td>\n",
       "      <td>0.063910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020267</td>\n",
       "      <td>-0.042627</td>\n",
       "      <td>-0.046244</td>\n",
       "      <td>-0.080441</td>\n",
       "      <td>-0.086688</td>\n",
       "      <td>-0.021254</td>\n",
       "      <td>-0.094580</td>\n",
       "      <td>-0.140943</td>\n",
       "      <td>-0.095567</td>\n",
       "      <td>-0.078468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.154096</td>\n",
       "      <td>-0.256358</td>\n",
       "      <td>-0.205721</td>\n",
       "      <td>-0.173496</td>\n",
       "      <td>-0.089319</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>-0.053149</td>\n",
       "      <td>-0.086360</td>\n",
       "      <td>0.179983</td>\n",
       "      <td>0.233909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.132633</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.068514</td>\n",
       "      <td>0.086270</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.090215</td>\n",
       "      <td>0.091860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195108</td>\n",
       "      <td>0.140525</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>-0.007772</td>\n",
       "      <td>-0.080112</td>\n",
       "      <td>-0.040983</td>\n",
       "      <td>-0.065315</td>\n",
       "      <td>-0.125160</td>\n",
       "      <td>-0.215256</td>\n",
       "      <td>-0.171852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137655</td>\n",
       "      <td>-0.091621</td>\n",
       "      <td>-0.082743</td>\n",
       "      <td>-0.081427</td>\n",
       "      <td>-0.074522</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>-0.083729</td>\n",
       "      <td>-0.075837</td>\n",
       "      <td>-0.067617</td>\n",
       "      <td>-0.076495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.083071</td>\n",
       "      <td>0.150060</td>\n",
       "      <td>0.374314</td>\n",
       "      <td>0.233909</td>\n",
       "      <td>0.387796</td>\n",
       "      <td>0.306906</td>\n",
       "      <td>0.152691</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>-0.126147</td>\n",
       "      <td>-0.480612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.082324</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.061937</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.081009</td>\n",
       "      <td>0.058649</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>-0.037366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.127462</td>\n",
       "      <td>-0.118913</td>\n",
       "      <td>-0.132394</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>-0.066631</td>\n",
       "      <td>-0.138642</td>\n",
       "      <td>-0.472721</td>\n",
       "      <td>-0.310285</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.178100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080441</td>\n",
       "      <td>-0.079454</td>\n",
       "      <td>-0.064329</td>\n",
       "      <td>-0.050519</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.070486</td>\n",
       "      <td>0.101724</td>\n",
       "      <td>0.090215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>0.243445</td>\n",
       "      <td>0.567988</td>\n",
       "      <td>0.807038</td>\n",
       "      <td>1.061872</td>\n",
       "      <td>1.068120</td>\n",
       "      <td>0.450271</td>\n",
       "      <td>0.805723</td>\n",
       "      <td>1.821771</td>\n",
       "      <td>1.391019</td>\n",
       "      <td>1.202278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104355</td>\n",
       "      <td>0.104683</td>\n",
       "      <td>0.108958</td>\n",
       "      <td>0.103368</td>\n",
       "      <td>0.101395</td>\n",
       "      <td>0.103697</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.105670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>1.629084</td>\n",
       "      <td>0.764621</td>\n",
       "      <td>0.997753</td>\n",
       "      <td>1.427189</td>\n",
       "      <td>0.668606</td>\n",
       "      <td>0.810327</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.050429</td>\n",
       "      <td>0.085612</td>\n",
       "      <td>2.057205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105670</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.102711</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.105670</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.102382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>1.678735</td>\n",
       "      <td>1.572198</td>\n",
       "      <td>1.297306</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>2.180841</td>\n",
       "      <td>1.531754</td>\n",
       "      <td>1.346629</td>\n",
       "      <td>1.606066</td>\n",
       "      <td>1.431464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103697</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.102382</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.109945</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.101724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>0.627175</td>\n",
       "      <td>-0.592410</td>\n",
       "      <td>0.845839</td>\n",
       "      <td>0.445996</td>\n",
       "      <td>0.637040</td>\n",
       "      <td>0.799147</td>\n",
       "      <td>0.290794</td>\n",
       "      <td>0.605144</td>\n",
       "      <td>0.761990</td>\n",
       "      <td>0.776458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108629</td>\n",
       "      <td>0.102382</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.101724</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.107643</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>1.635989</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>1.196030</td>\n",
       "      <td>1.506106</td>\n",
       "      <td>1.729045</td>\n",
       "      <td>1.654074</td>\n",
       "      <td>1.467305</td>\n",
       "      <td>1.860901</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.834002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098436</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.103368</td>\n",
       "      <td>0.104026</td>\n",
       "      <td>0.096463</td>\n",
       "      <td>0.105341</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.104355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8800 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.067198  0.071802  0.226346  0.034974  0.051415  0.035632  0.078049   \n",
       "1    -0.154096 -0.256358 -0.205721 -0.173496 -0.089319  0.004394 -0.053149   \n",
       "2     0.195108  0.140525  0.003079 -0.007772 -0.080112 -0.040983 -0.065315   \n",
       "3    -0.083071  0.150060  0.374314  0.233909  0.387796  0.306906  0.152691   \n",
       "4    -0.127462 -0.118913 -0.132394 -0.068275 -0.066631 -0.138642 -0.472721   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8795  0.243445  0.567988  0.807038  1.061872  1.068120  0.450271  0.805723   \n",
       "8796  1.629084  0.764621  0.997753  1.427189  0.668606  0.810327  0.935606   \n",
       "8797  1.678735  1.572198  1.297306  0.636711  1.701424  2.180841  1.531754   \n",
       "8798  0.627175 -0.592410  0.845839  0.445996  0.637040  0.799147  0.290794   \n",
       "8799  1.635989  1.701424  1.196030  1.506106  1.729045  1.654074  1.467305   \n",
       "\n",
       "             7         8         9  ...    1014.1    1015.1    1016.1  \\\n",
       "0     0.191163  0.102382  0.063910  ... -0.020267 -0.042627 -0.046244   \n",
       "1    -0.086360  0.179983  0.233909  ...  0.085941  0.065225  0.132633   \n",
       "2    -0.125160 -0.215256 -0.171852  ... -0.137655 -0.091621 -0.082743   \n",
       "3     0.050100 -0.126147 -0.480612  ...  0.085941  0.082324  0.078707   \n",
       "4    -0.310285 -0.183361 -0.178100  ... -0.080441 -0.079454 -0.064329   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8795  1.821771  1.391019  1.202278  ...  0.104355  0.104683  0.108958   \n",
       "8796  0.050429  0.085612  2.057205  ...  0.105670  0.100080  0.103039   \n",
       "8797  1.346629  1.606066  1.431464  ...  0.103697  0.106656  0.102382   \n",
       "8798  0.605144  0.761990  0.776458  ...  0.108629  0.102382  0.099422   \n",
       "8799  1.860901  1.075683  0.834002  ...  0.098436  0.100409  0.103368   \n",
       "\n",
       "        1017.1    1018.1    1019.1    1020.1    1021.1    1022.1    1023.1  \n",
       "0    -0.080441 -0.086688 -0.021254 -0.094580 -0.140943 -0.095567 -0.078468  \n",
       "1     0.100080  0.068514  0.086270  0.083310  0.086598  0.090215  0.091860  \n",
       "2    -0.081427 -0.074522 -0.099512 -0.083729 -0.075837 -0.067617 -0.076495  \n",
       "3     0.061937  0.074761  0.081009  0.058649  0.042537  0.003736 -0.037366  \n",
       "4    -0.050519 -0.017308  0.013601  0.031686  0.070486  0.101724  0.090215  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "8795  0.103368  0.101395  0.103697  0.105012  0.099422  0.100738  0.105670  \n",
       "8796  0.106656  0.102711  0.100738  0.101066  0.105670  0.100080  0.102382  \n",
       "8797  0.101066  0.101066  0.109945  0.101066  0.100080  0.106656  0.101724  \n",
       "8798  0.106656  0.106656  0.101724  0.103039  0.107643  0.103039  0.099751  \n",
       "8799  0.104026  0.096463  0.105341  0.105012  0.100738  0.101066  0.104355  \n",
       "\n",
       "[8800 rows x 2048 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "1019.1    0\n",
       "1020.1    0\n",
       "1021.1    0\n",
       "1022.1    0\n",
       "1023.1    0\n",
       "Length: 2048, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(features_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 2048)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = features_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extracted_data.reshape(17600,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17600, 32, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# entire time domain data set of all faults together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_Class = []\n",
    "file_no=0\n",
    "for file in range(5):###total no of files are 5\n",
    "    file_no = file_no+1\n",
    "    for num_segment in range(2*1760): #segments for each file\n",
    "        fault='C'+str(file_no)\n",
    "        fault_Class.append(fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(fault_Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17600,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1' 'C2' 'C3' 'C4' 'C5']\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "category_labels = np.unique(labels)\n",
    "print(category_labels)\n",
    "labels = pd.Categorical(labels, categories = category_labels).codes\n",
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 1000, random_state = 829, \n",
    "                                                                    stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16600, 32, 32), (16600,), (1000,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,train_labels.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16600, 32, 32, 1) (16600, 5) (1000, 32, 32, 1) (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "train_data = train_data.reshape(len(train_data),32,32,1)\n",
    "test_data = test_data.reshape(len(test_data),32,32,1)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Shuffle data\n",
    "index = np.random.permutation(len(train_labels))\n",
    "train_data, train_labels = train_data[index], train_labels[index]\n",
    "\n",
    "print(train_data.shape, train_labels.shape, test_data.shape, test_labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 32)        2624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 32)          82976     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 96)                6240      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 485       \n",
      "=================================================================\n",
      "Total params: 100,581\n",
      "Trainable params: 100,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "demo_model = Sequential([\n",
    "    layers.Conv2D(32,9,activation= 'relu', input_shape = (32,32,1)),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Conv2D(32,9,activation = 'relu'),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation = 'relu'),\n",
    "    layers.Dense(96, activation = 'relu'),\n",
    "    layers.Dense(5, activation = 'softmax')\n",
    "])\n",
    "demo_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "    layers.Conv2D(32,9,activation= 'relu', input_shape = (32,32,1)),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Conv2D(32,9,activation = 'relu'),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation = 'relu'),\n",
    "    layers.Dense(96, activation = 'relu'),\n",
    "    layers.Dense(5, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001), \n",
    "                  metrics= ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.7432 - accuracy: 0.5805\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.5051 - accuracy: 0.6813\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4307 - accuracy: 0.7068\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.4251 - accuracy: 0.7245\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.3959 - accuracy: 0.7519\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3776 - accuracy: 0.7721\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3482 - accuracy: 0.7998\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3198 - accuracy: 0.8216\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3045 - accuracy: 0.8337\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2881 - accuracy: 0.8374\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2661 - accuracy: 0.8487\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2688 - accuracy: 0.8549\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2712 - accuracy: 0.8512\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2626 - accuracy: 0.8508\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2423 - accuracy: 0.8592\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2282 - accuracy: 0.8719\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2200 - accuracy: 0.8751\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2121 - accuracy: 0.8777\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2091 - accuracy: 0.8783\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2041 - accuracy: 0.8795\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1918 - accuracy: 0.8910\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1827 - accuracy: 0.8988\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2047 - accuracy: 0.8869\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1748 - accuracy: 0.9005\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1731 - accuracy: 0.8986\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1620 - accuracy: 0.9050\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1579 - accuracy: 0.9145\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1532 - accuracy: 0.9154\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1496 - accuracy: 0.9172\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1583 - accuracy: 0.9152\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2324 - accuracy: 0.8872\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1648 - accuracy: 0.8996\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1644 - accuracy: 0.9039\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1516 - accuracy: 0.9094\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1517 - accuracy: 0.9066\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1467 - accuracy: 0.9155\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1506 - accuracy: 0.9184\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1466 - accuracy: 0.9193\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1436 - accuracy: 0.9208\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1488 - accuracy: 0.9152\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1443 - accuracy: 0.9156\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1393 - accuracy: 0.9230\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1378 - accuracy: 0.9223\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1441 - accuracy: 0.9192\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2411 - accuracy: 0.8955\n",
      "Training time: 832.6726212501526s\n",
      "Loop iteration 1, Accuracy: 0.9060\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.6309 - accuracy: 0.6569\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4373 - accuracy: 0.7166\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4241 - accuracy: 0.7225\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4017 - accuracy: 0.7474\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4655 - accuracy: 0.7511\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3903 - accuracy: 0.7617\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3691 - accuracy: 0.7776\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3456 - accuracy: 0.7942\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3351 - accuracy: 0.8063\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3208 - accuracy: 0.8117\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2986 - accuracy: 0.8292\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2937 - accuracy: 0.8266\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2712 - accuracy: 0.8433\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2551 - accuracy: 0.8538\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2691 - accuracy: 0.8449\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2541 - accuracy: 0.8573\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2411 - accuracy: 0.8648\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2320 - accuracy: 0.8730\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2390 - accuracy: 0.8679\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2129 - accuracy: 0.8748\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2184 - accuracy: 0.8758\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2094 - accuracy: 0.8848\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2061 - accuracy: 0.8884\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1929 - accuracy: 0.8875\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1967 - accuracy: 0.8987\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1757 - accuracy: 0.8980\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2201 - accuracy: 0.8866\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1680 - accuracy: 0.9034\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1723 - accuracy: 0.9023\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1666 - accuracy: 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1616 - accuracy: 0.9068\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1583 - accuracy: 0.9094\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1641 - accuracy: 0.9055\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1598 - accuracy: 0.9075\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1583 - accuracy: 0.9061\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1587 - accuracy: 0.9136\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1467 - accuracy: 0.9226\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1495 - accuracy: 0.9183\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1659 - accuracy: 0.9140\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1515 - accuracy: 0.9197\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1493 - accuracy: 0.9098\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2194 - accuracy: 0.8984\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1565 - accuracy: 0.9151\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1477 - accuracy: 0.9196\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1362 - accuracy: 0.9254\n",
      "Training time: 830.5677897930145s\n",
      "Loop iteration 2, Accuracy: 0.8750\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.7371 - accuracy: 0.5979\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.6063 - accuracy: 0.6855\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4206 - accuracy: 0.7188\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4111 - accuracy: 0.7332\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3886 - accuracy: 0.7639\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3804 - accuracy: 0.7696s -\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3689 - accuracy: 0.7852\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3491 - accuracy: 0.8063\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3407 - accuracy: 0.8143\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3215 - accuracy: 0.8285\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3197 - accuracy: 0.8284\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3042 - accuracy: 0.8411\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3126 - accuracy: 0.8410\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2878 - accuracy: 0.8530\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2683 - accuracy: 0.8648\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2616 - accuracy: 0.8699\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2695 - accuracy: 0.8470\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2704 - accuracy: 0.8518\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2506 - accuracy: 0.8570\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2358 - accuracy: 0.8701\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2389 - accuracy: 0.8726\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2348 - accuracy: 0.8640\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2207 - accuracy: 0.8705\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 28s 2ms/sample - loss: 0.2284 - accuracy: 0.8704\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.2155 - accuracy: 0.8808\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2114 - accuracy: 0.8795\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2018 - accuracy: 0.8901\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2047 - accuracy: 0.8887\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1993 - accuracy: 0.8865\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.2113 - accuracy: 0.8824\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1830 - accuracy: 0.9014\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1891 - accuracy: 0.8954\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1840 - accuracy: 0.8948\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1845 - accuracy: 0.8942\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1828 - accuracy: 0.8986\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1790 - accuracy: 0.9014\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1848 - accuracy: 0.9012\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1897 - accuracy: 0.9028\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1678 - accuracy: 0.9081\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1812 - accuracy: 0.9009\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1626 - accuracy: 0.9075\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1518 - accuracy: 0.9197\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1587 - accuracy: 0.9063\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1554 - accuracy: 0.9184\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1659 - accuracy: 0.9077\n",
      "Training time: 879.8163850307465s\n",
      "Loop iteration 3, Accuracy: 0.9030\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.6703 - accuracy: 0.6343\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4475 - accuracy: 0.7140\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.4176 - accuracy: 0.7301\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4199 - accuracy: 0.7284\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3931 - accuracy: 0.7566\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3791 - accuracy: 0.7675\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3626 - accuracy: 0.7827\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.4153 - accuracy: 0.7793\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3495 - accuracy: 0.7875\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3178 - accuracy: 0.8135\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3124 - accuracy: 0.8110\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2978 - accuracy: 0.8277\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2817 - accuracy: 0.8343\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2809 - accuracy: 0.8387\n",
      "Epoch 15/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2672 - accuracy: 0.8399\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2599 - accuracy: 0.8499\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2646 - accuracy: 0.8476\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2374 - accuracy: 0.8595\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2345 - accuracy: 0.8617\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2298 - accuracy: 0.8688\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2097 - accuracy: 0.8728\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2257 - accuracy: 0.8733\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2306 - accuracy: 0.8679\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1941 - accuracy: 0.8804\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1982 - accuracy: 0.8813\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1831 - accuracy: 0.8908\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1786 - accuracy: 0.8904\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1775 - accuracy: 0.9004\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1849 - accuracy: 0.8896\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1593 - accuracy: 0.9021\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1618 - accuracy: 0.9001\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1672 - accuracy: 0.9013\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1594 - accuracy: 0.9065\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1623 - accuracy: 0.9110\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1565 - accuracy: 0.9047\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1516 - accuracy: 0.9159\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1451 - accuracy: 0.9168\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1546 - accuracy: 0.9111\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1432 - accuracy: 0.9202\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1423 - accuracy: 0.9214\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2493 - accuracy: 0.9016\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1801 - accuracy: 0.9025\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1499 - accuracy: 0.9170\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1415 - accuracy: 0.9264\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1508 - accuracy: 0.9214\n",
      "Training time: 863.5969295501709s\n",
      "Loop iteration 4, Accuracy: 0.8710\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.6501 - accuracy: 0.6501\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.4395 - accuracy: 0.7133\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.4360 - accuracy: 0.7275\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4042 - accuracy: 0.7528\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3932 - accuracy: 0.7722\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3710 - accuracy: 0.7917\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3488 - accuracy: 0.8064\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3383 - accuracy: 0.8131\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3226 - accuracy: 0.8178\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3067 - accuracy: 0.8270\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2947 - accuracy: 0.8334\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2818 - accuracy: 0.8384\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2866 - accuracy: 0.8423s - loss: 0.2873 \n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2636 - accuracy: 0.8513\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2618 - accuracy: 0.8501\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2644 - accuracy: 0.8487\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2421 - accuracy: 0.8667\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2288 - accuracy: 0.8740\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2199 - accuracy: 0.8739\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2323 - accuracy: 0.8733\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2085 - accuracy: 0.8819\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2034 - accuracy: 0.8858\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1950 - accuracy: 0.8955\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1925 - accuracy: 0.8961\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1749 - accuracy: 0.8943\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1769 - accuracy: 0.8991\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1911 - accuracy: 0.8934\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1600 - accuracy: 0.9161\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1784 - accuracy: 0.9028\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1620 - accuracy: 0.9099\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.3182 - accuracy: 0.8703\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1763 - accuracy: 0.8831\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1668 - accuracy: 0.8872\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1596 - accuracy: 0.8957\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1581 - accuracy: 0.8992\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1518 - accuracy: 0.9083\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1539 - accuracy: 0.9064\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1523 - accuracy: 0.9108\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1471 - accuracy: 0.9142\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1442 - accuracy: 0.9190\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1582 - accuracy: 0.9048\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2065 - accuracy: 0.8983\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1507 - accuracy: 0.9150\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1443 - accuracy: 0.9205\n",
      "Epoch 45/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1460 - accuracy: 0.9145\n",
      "Training time: 883.4975538253784s\n",
      "Loop iteration 5, Accuracy: 0.8930\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.7324 - accuracy: 0.6134\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4860 - accuracy: 0.7083\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4221 - accuracy: 0.7307\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4147 - accuracy: 0.7369\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3959 - accuracy: 0.7611\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3764 - accuracy: 0.7810\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3745 - accuracy: 0.7760\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3513 - accuracy: 0.7982\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3264 - accuracy: 0.8132\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3038 - accuracy: 0.8289\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2895 - accuracy: 0.8343\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2703 - accuracy: 0.8479\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2721 - accuracy: 0.8487\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2427 - accuracy: 0.8634\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2431 - accuracy: 0.8680\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2226 - accuracy: 0.8698\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2250 - accuracy: 0.8722\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2249 - accuracy: 0.8705\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2345 - accuracy: 0.8660\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2115 - accuracy: 0.8767\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1971 - accuracy: 0.8855\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2006 - accuracy: 0.8830\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1986 - accuracy: 0.8845\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1970 - accuracy: 0.8848\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1933 - accuracy: 0.8836\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1734 - accuracy: 0.8960\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1815 - accuracy: 0.8957\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2030 - accuracy: 0.8806\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1692 - accuracy: 0.8951\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1810 - accuracy: 0.8943\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1880 - accuracy: 0.8842\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1657 - accuracy: 0.9017\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1980 - accuracy: 0.8917\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1579 - accuracy: 0.9006\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1569 - accuracy: 0.9002\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1577 - accuracy: 0.9058\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1533 - accuracy: 0.9113\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1545 - accuracy: 0.9060\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1922 - accuracy: 0.8826\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1544 - accuracy: 0.9014\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1492 - accuracy: 0.9138\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1508 - accuracy: 0.9107\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1641 - accuracy: 0.8846\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2267 - accuracy: 0.8742\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1580 - accuracy: 0.9038\n",
      "Training time: 874.6221649646759s\n",
      "Loop iteration 6, Accuracy: 0.8950\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.7371 - accuracy: 0.5845\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4940 - accuracy: 0.6981\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4216 - accuracy: 0.7281s - loss: 0.4231 - \n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.4042 - accuracy: 0.7472\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.3770 - accuracy: 0.7752\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.3367 - accuracy: 0.8108\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3126 - accuracy: 0.8274\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3006 - accuracy: 0.8449\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 28s 2ms/sample - loss: 0.2760 - accuracy: 0.8534\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.2627 - accuracy: 0.8610\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2617 - accuracy: 0.8621\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2541 - accuracy: 0.8620\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2545 - accuracy: 0.8655\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.2458 - accuracy: 0.8651\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2363 - accuracy: 0.8701\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2348 - accuracy: 0.8720\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2135 - accuracy: 0.8814\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2059 - accuracy: 0.8836\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2359 - accuracy: 0.8793\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2167 - accuracy: 0.8817\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1946 - accuracy: 0.8943\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1934 - accuracy: 0.8948\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1882 - accuracy: 0.8950\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1983 - accuracy: 0.8936\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 30s 2ms/sample - loss: 0.1703 - accuracy: 0.9075s - loss: 0\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1756 - accuracy: 0.9058\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1583 - accuracy: 0.9172\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1567 - accuracy: 0.9170\n",
      "Epoch 29/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1626 - accuracy: 0.9073\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1743 - accuracy: 0.9080\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1533 - accuracy: 0.9180\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1617 - accuracy: 0.9085\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1756 - accuracy: 0.9010\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1723 - accuracy: 0.9122\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1477 - accuracy: 0.9181\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1457 - accuracy: 0.9193\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1490 - accuracy: 0.9083\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1493 - accuracy: 0.9119\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1462 - accuracy: 0.9238\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1751 - accuracy: 0.9093\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1537 - accuracy: 0.9193\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1385 - accuracy: 0.9258\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1428 - accuracy: 0.9212\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1310 - accuracy: 0.9299\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1329 - accuracy: 0.9272\n",
      "Training time: 910.4440891742706s\n",
      "Loop iteration 7, Accuracy: 0.9100\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.7089 - accuracy: 0.6055\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4848 - accuracy: 0.7092\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4044 - accuracy: 0.7583\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.6149 - accuracy: 0.7290\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3753 - accuracy: 0.7755\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3619 - accuracy: 0.7828\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3416 - accuracy: 0.8000\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.3496 - accuracy: 0.7929\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3094 - accuracy: 0.8248\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.3034 - accuracy: 0.8259\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.2863 - accuracy: 0.8317\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.2807 - accuracy: 0.8344\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 28s 2ms/sample - loss: 0.2753 - accuracy: 0.8431\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.2559 - accuracy: 0.8549\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.2734 - accuracy: 0.8420\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.2432 - accuracy: 0.8571\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2409 - accuracy: 0.8633\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2368 - accuracy: 0.8595\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2259 - accuracy: 0.8647\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 29s 2ms/sample - loss: 0.2163 - accuracy: 0.8752\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.2161 - accuracy: 0.8714\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2345 - accuracy: 0.8627\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.2079 - accuracy: 0.8773\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2080 - accuracy: 0.8804\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2091 - accuracy: 0.8750\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.1949 - accuracy: 0.8821\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1809 - accuracy: 0.8875s - loss: 0.1\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1912 - accuracy: 0.8836\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1752 - accuracy: 0.8952\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 25s 2ms/sample - loss: 0.1956 - accuracy: 0.8833\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1704 - accuracy: 0.8941\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1760 - accuracy: 0.8898\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 25s 2ms/sample - loss: 0.1625 - accuracy: 0.9010\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1653 - accuracy: 0.9004\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1564 - accuracy: 0.9076\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1625 - accuracy: 0.9031\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.1570 - accuracy: 0.9063\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.1797 - accuracy: 0.8931\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 27s 2ms/sample - loss: 0.1714 - accuracy: 0.8981\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1561 - accuracy: 0.9033\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1531 - accuracy: 0.9114\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2547 - accuracy: 0.8759\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1705 - accuracy: 0.8876\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1711 - accuracy: 0.8902\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1550 - accuracy: 0.8956\n",
      "Training time: 995.6492786407471s\n",
      "Loop iteration 8, Accuracy: 0.8700\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.7171 - accuracy: 0.6081\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4690 - accuracy: 0.7149\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.4688 - accuracy: 0.7227\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.3865 - accuracy: 0.7579\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 29s 2ms/sample - loss: 0.3702 - accuracy: 0.7775\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.3730 - accuracy: 0.7753\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 30s 2ms/sample - loss: 0.3520 - accuracy: 0.7943\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 32s 2ms/sample - loss: 0.3412 - accuracy: 0.8000\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.3313 - accuracy: 0.8087\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3116 - accuracy: 0.8245\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2916 - accuracy: 0.8372\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.2823 - accuracy: 0.8434\n",
      "Epoch 13/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.2836 - accuracy: 0.8434\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.2693 - accuracy: 0.8520\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2564 - accuracy: 0.8530\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2724 - accuracy: 0.8493\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2295 - accuracy: 0.8702\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2192 - accuracy: 0.8752\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2181 - accuracy: 0.8779\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2217 - accuracy: 0.8723\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2018 - accuracy: 0.8886\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2216 - accuracy: 0.8773\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1913 - accuracy: 0.8923\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1921 - accuracy: 0.8881\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1866 - accuracy: 0.8946\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1844 - accuracy: 0.8967\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1790 - accuracy: 0.8955\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1912 - accuracy: 0.8949\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1724 - accuracy: 0.8977\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1667 - accuracy: 0.9014\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1633 - accuracy: 0.9065\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1602 - accuracy: 0.9102\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1664 - accuracy: 0.9040\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1612 - accuracy: 0.9005\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1616 - accuracy: 0.9022s - los\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1544 - accuracy: 0.9125\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.1464 - accuracy: 0.9110\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.1510 - accuracy: 0.9122\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1510 - accuracy: 0.9141\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1626 - accuracy: 0.9054\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1536 - accuracy: 0.9086\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1429 - accuracy: 0.9210\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1563 - accuracy: 0.9075\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1416 - accuracy: 0.9247\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1778 - accuracy: 0.9105\n",
      "Training time: 961.9566876888275s\n",
      "Loop iteration 9, Accuracy: 0.8710\n",
      "Train on 16600 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.7232 - accuracy: 0.6142\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4499 - accuracy: 0.7117\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4207 - accuracy: 0.7283\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4469 - accuracy: 0.7369\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4037 - accuracy: 0.7496\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3799 - accuracy: 0.7776\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3650 - accuracy: 0.7921\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3436 - accuracy: 0.8128\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3356 - accuracy: 0.8172\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3193 - accuracy: 0.8342\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3022 - accuracy: 0.8401\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.3129 - accuracy: 0.8259\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2834 - accuracy: 0.8415\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2774 - accuracy: 0.8480\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2765 - accuracy: 0.8455\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2650 - accuracy: 0.8569\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2630 - accuracy: 0.8560\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2449 - accuracy: 0.8691\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2461 - accuracy: 0.8631\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2271 - accuracy: 0.8746\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2149 - accuracy: 0.8833\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2284 - accuracy: 0.8743\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2120 - accuracy: 0.8806\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2085 - accuracy: 0.8872\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2098 - accuracy: 0.8906\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2226 - accuracy: 0.8896\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2022 - accuracy: 0.8878\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1936 - accuracy: 0.8945\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1880 - accuracy: 0.8937\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1792 - accuracy: 0.9025\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1711 - accuracy: 0.9150\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1759 - accuracy: 0.9118\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1679 - accuracy: 0.9072\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1743 - accuracy: 0.9037\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1704 - accuracy: 0.9104\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1533 - accuracy: 0.9202\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.2804 - accuracy: 0.8988\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1764 - accuracy: 0.8870\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1612 - accuracy: 0.8932\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1834 - accuracy: 0.8963\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1673 - accuracy: 0.9093\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.1681 - accuracy: 0.9064\n",
      "Epoch 43/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1495 - accuracy: 0.9200\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1538 - accuracy: 0.9187\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1488 - accuracy: 0.9148\n",
      "Training time: 817.18448138237s\n",
      "Loop iteration 10, Accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "res = np.empty(10)\n",
    "res[:] = np.nan\n",
    "for i in range(10):\n",
    "    model = create_compiled_model()\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    history = model.fit(train_data, train_labels, epochs = 45, batch_size = 128, verbose = 1)    # Verbosity is set to zero\n",
    "    \n",
    "    stop = time.time()\n",
    "    print(f\"Training time: {stop - start}s\")\n",
    "    \n",
    "    res[i] = model.evaluate(test_data, test_labels, batch_size = 128, verbose = 0)[1]            # Verbosity is set to zero\n",
    "    print('Loop iteration %d, Accuracy: %4.4f' % (i+1, res[i]))\n",
    "    if res[i]>=np.max(res[:(i+1)]):\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:0.8894\n",
      "Best accuracy: 0.9100\n",
      "Worst accuracy: 0.8700\n",
      "Standard deviation: 0.0152\n"
     ]
    }
   ],
   "source": [
    "print('Average accuracy:%4.4f'%(np.mean(res))) # After running the model 10 times\n",
    "print(\"Best accuracy: %4.4f\"%(np.max(res)))\n",
    "print(\"Worst accuracy: %4.4f\"%(np.min(res)))\n",
    "print('Standard deviation: %4.4f' % (np.std(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##based on validation loss .w.e need to stop the trg\n",
    "# we dont want to train on same model..need to recreate the model fresh\n",
    "\n",
    "model = create_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.EarlyStopping at 0xc92f6f0c08>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)\n",
    "# we are trying to min the thing that we are monitoring\n",
    "early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16600 samples, validate on 1000 samples\n",
      "Epoch 1/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.7047 - accuracy: 0.5977 - val_loss: 0.5790 - val_accuracy: 0.7080\n",
      "Epoch 2/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.5986 - accuracy: 0.6863 - val_loss: 0.4993 - val_accuracy: 0.7080\n",
      "Epoch 3/45\n",
      "16600/16600 [==============================] - 18s 1ms/sample - loss: 0.4310 - accuracy: 0.7192 - val_loss: 0.4206 - val_accuracy: 0.7240\n",
      "Epoch 4/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.4061 - accuracy: 0.7516 - val_loss: 0.4324 - val_accuracy: 0.6900\n",
      "Epoch 5/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3879 - accuracy: 0.7696 - val_loss: 0.4235 - val_accuracy: 0.7630\n",
      "Epoch 6/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.3634 - accuracy: 0.7982 - val_loss: 0.3632 - val_accuracy: 0.7890\n",
      "Epoch 7/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3390 - accuracy: 0.8172 - val_loss: 0.3094 - val_accuracy: 0.8270\n",
      "Epoch 8/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3135 - accuracy: 0.8371 - val_loss: 0.3414 - val_accuracy: 0.8190\n",
      "Epoch 9/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3055 - accuracy: 0.8384 - val_loss: 0.2863 - val_accuracy: 0.8380\n",
      "Epoch 10/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.3067 - accuracy: 0.8325 - val_loss: 0.2871 - val_accuracy: 0.8350\n",
      "Epoch 11/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2846 - accuracy: 0.8351 - val_loss: 0.2542 - val_accuracy: 0.8530\n",
      "Epoch 12/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2637 - accuracy: 0.8517 - val_loss: 0.2630 - val_accuracy: 0.8570\n",
      "Epoch 13/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2674 - accuracy: 0.8553 - val_loss: 0.2398 - val_accuracy: 0.8940\n",
      "Epoch 14/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2713 - accuracy: 0.8528 - val_loss: 0.2375 - val_accuracy: 0.8800\n",
      "Epoch 15/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2599 - accuracy: 0.8634 - val_loss: 0.2381 - val_accuracy: 0.8620\n",
      "Epoch 16/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2374 - accuracy: 0.8759 - val_loss: 0.2178 - val_accuracy: 0.9010\n",
      "Epoch 17/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2394 - accuracy: 0.8807 - val_loss: 0.2440 - val_accuracy: 0.8460\n",
      "Epoch 18/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2280 - accuracy: 0.8654 - val_loss: 0.2235 - val_accuracy: 0.8690\n",
      "Epoch 19/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2202 - accuracy: 0.8752 - val_loss: 0.2218 - val_accuracy: 0.8620\n",
      "Epoch 20/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.2201 - accuracy: 0.8773 - val_loss: 0.2063 - val_accuracy: 0.9010\n",
      "Epoch 21/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.2188 - accuracy: 0.8795 - val_loss: 0.2500 - val_accuracy: 0.8900\n",
      "Epoch 22/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2248 - accuracy: 0.8748 - val_loss: 0.2598 - val_accuracy: 0.8630\n",
      "Epoch 23/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2011 - accuracy: 0.8919 - val_loss: 0.2335 - val_accuracy: 0.8680\n",
      "Epoch 24/45\n",
      "16600/16600 [==============================] - 25s 1ms/sample - loss: 0.2070 - accuracy: 0.8822 - val_loss: 0.2180 - val_accuracy: 0.8640\n",
      "Epoch 25/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.1977 - accuracy: 0.8807 - val_loss: 0.2437 - val_accuracy: 0.8660\n",
      "Epoch 26/45\n",
      "16600/16600 [==============================] - 27s 2ms/sample - loss: 0.2143 - accuracy: 0.8775 - val_loss: 0.2190 - val_accuracy: 0.8660\n",
      "Epoch 27/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1800 - accuracy: 0.8977 - val_loss: 0.2069 - val_accuracy: 0.9150\n",
      "Epoch 28/45\n",
      "16600/16600 [==============================] - 26s 2ms/sample - loss: 0.1917 - accuracy: 0.8953 - val_loss: 0.2263 - val_accuracy: 0.8800\n",
      "Epoch 29/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1744 - accuracy: 0.9077 - val_loss: 0.2639 - val_accuracy: 0.8800\n",
      "Epoch 30/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.2035 - accuracy: 0.8894 - val_loss: 0.2191 - val_accuracy: 0.8710\n",
      "Epoch 31/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1768 - accuracy: 0.9055 - val_loss: 0.2200 - val_accuracy: 0.8960\n",
      "Epoch 32/45\n",
      "16600/16600 [==============================] - 25s 2ms/sample - loss: 0.1751 - accuracy: 0.9042 - val_loss: 0.2177 - val_accuracy: 0.8860\n",
      "Epoch 33/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1641 - accuracy: 0.9121 - val_loss: 0.2337 - val_accuracy: 0.8750\n",
      "Epoch 34/45\n",
      "16600/16600 [==============================] - 21s 1ms/sample - loss: 0.1606 - accuracy: 0.9046 - val_loss: 0.2106 - val_accuracy: 0.8820\n",
      "Epoch 35/45\n",
      "16600/16600 [==============================] - 19s 1ms/sample - loss: 0.1606 - accuracy: 0.9128 - val_loss: 0.2202 - val_accuracy: 0.8900\n",
      "Epoch 36/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1558 - accuracy: 0.9081 - val_loss: 0.2660 - val_accuracy: 0.8620\n",
      "Epoch 37/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1777 - accuracy: 0.9092 - val_loss: 0.2096 - val_accuracy: 0.9120\n",
      "Epoch 38/45\n",
      "16600/16600 [==============================] - 25s 2ms/sample - loss: 0.1667 - accuracy: 0.9108 - val_loss: 0.2285 - val_accuracy: 0.9070\n",
      "Epoch 39/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1466 - accuracy: 0.9195 - val_loss: 0.2274 - val_accuracy: 0.8900\n",
      "Epoch 40/45\n",
      "16600/16600 [==============================] - 23s 1ms/sample - loss: 0.1444 - accuracy: 0.9196 - val_loss: 0.2035 - val_accuracy: 0.9040\n",
      "Epoch 41/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1433 - accuracy: 0.9223 - val_loss: 0.2255 - val_accuracy: 0.9120\n",
      "Epoch 42/45\n",
      "16600/16600 [==============================] - 24s 1ms/sample - loss: 0.1433 - accuracy: 0.9134 - val_loss: 0.2379 - val_accuracy: 0.9030\n",
      "Epoch 43/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1528 - accuracy: 0.9178 - val_loss: 0.2623 - val_accuracy: 0.8530\n",
      "Epoch 44/45\n",
      "16600/16600 [==============================] - 22s 1ms/sample - loss: 0.1545 - accuracy: 0.9154 - val_loss: 0.2226 - val_accuracy: 0.9100\n",
      "Epoch 45/45\n",
      "16600/16600 [==============================] - 20s 1ms/sample - loss: 0.1675 - accuracy: 0.9077 - val_loss: 0.2159 - val_accuracy: 0.8710\n",
      "Training time: 946.2704405784607s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc94177ae88>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model.fit(train_data, train_labels,epochs=45,validation_data=(test_data,test_labels)\n",
    "          ,callbacks=[early_stop],batch_size = 128, verbose = 1)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
